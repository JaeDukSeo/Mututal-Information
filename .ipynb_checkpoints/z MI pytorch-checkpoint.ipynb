{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "import argparse, math, sys\n",
    "from copy import deepcopy\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     2,
     47,
     78,
     112,
     141,
     169
    ]
   },
   "outputs": [],
   "source": [
    "# declare functions\n",
    "\n",
    "def entropy(target):\n",
    "    probas = []\n",
    "    for k in range(target.max() + 1):\n",
    "        n = (target == k).sum().item()\n",
    "        if n > 0: probas.append(n)\n",
    "    probas = torch.tensor(probas).float()\n",
    "    probas /= probas.sum()\n",
    "    return - (probas * probas.log()).sum().item()\n",
    "\n",
    "# Returns a triplet of tensors (a, b, c), where a and b contain each\n",
    "# half of the samples, with a[i] and b[i] of same class for any i, and\n",
    "# c is a 1d long tensor real classes\n",
    "def create_image_pairs(train = False):\n",
    "    ua, ub, uc = [], [], []\n",
    "\n",
    "    if train: input, target = train_input, train_target\n",
    "    else:     input, target = test_input, test_target\n",
    "\n",
    "    for i in used_MNIST_classes:\n",
    "        used_indices = torch.arange(input.size(0), device = target.device).masked_select(target == i.item())\n",
    "        x = input[used_indices]\n",
    "        x = x[torch.randperm(x.size(0))]\n",
    "        hs = x.size(0)//2\n",
    "        ua.append(x.narrow(0, 0, hs))\n",
    "        ub.append(x.narrow(0, hs, hs))\n",
    "        uc.append(target[used_indices])\n",
    "\n",
    "    a = torch.cat(ua, 0)\n",
    "    b = torch.cat(ub, 0)\n",
    "    c = torch.cat(uc, 0)\n",
    "    perm = torch.randperm(a.size(0))\n",
    "    a = a[perm].contiguous()\n",
    "\n",
    "    # if args.independent: perm = torch.randperm(a.size(0))\n",
    "    b = b[perm].contiguous()\n",
    "\n",
    "    return a, b, c\n",
    "\n",
    "# Returns a triplet a, b, c where a are the standard MNIST images, c\n",
    "# the classes, and b is a Nx2 tensor, with for every n:\n",
    "#   b[n, 0] ~ Uniform(0, 10)\n",
    "#   b[n, 1] ~ b[n, 0] + Uniform(0, 0.5) + c[n]\n",
    "def create_image_values_pairs(train = False):\n",
    "    ua, ub = [], []\n",
    "\n",
    "    if train:\n",
    "        input, target = train_input, train_target\n",
    "    else:\n",
    "        input, target = test_input, test_target\n",
    "\n",
    "    m = torch.zeros(used_MNIST_classes.max() + 1, dtype = torch.uint8, device = target.device)\n",
    "    m[used_MNIST_classes] = 1\n",
    "    m = m[target]\n",
    "    used_indices = torch.arange(input.size(0), device = target.device).masked_select(m)\n",
    "\n",
    "    input = input[used_indices].contiguous()\n",
    "    target = target[used_indices].contiguous()\n",
    "\n",
    "    a = input\n",
    "    c = target\n",
    "\n",
    "    b = a.new(a.size(0), 2)\n",
    "    b[:, 0].uniform_(0.0, 10.0)\n",
    "    b[:, 1].uniform_(0.0, 0.5)\n",
    "\n",
    "    if args.independent:\n",
    "        b[:, 1] += b[:, 0] + \\\n",
    "                   used_MNIST_classes[torch.randint(len(used_MNIST_classes), target.size())]\n",
    "    else:\n",
    "        b[:, 1] += b[:, 0] + target.float()\n",
    "\n",
    "    return a, b, c\n",
    "\n",
    "def create_sequences_pairs(train = False):\n",
    "    nb, length = 10000, 1024\n",
    "    noise_level = 2e-2\n",
    "\n",
    "    ha = torch.randint(args.nb_classes, (nb, ), device = device) + 1\n",
    "    if args.independent:\n",
    "        hb = torch.randint(args.nb_classes, (nb, ), device = device)\n",
    "    else:\n",
    "        hb = ha\n",
    "\n",
    "    pos = torch.empty(nb, device = device).uniform_(0.0, 0.9)\n",
    "    a = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    a = a - pos.view(nb, 1)\n",
    "    a = (a >= 0).float() * torch.exp(-a * math.log(2) / 0.1)\n",
    "    a = a * ha.float().view(-1, 1).expand_as(a) / (1 + args.nb_classes)\n",
    "    noise = a.new(a.size()).normal_(0, noise_level)\n",
    "    a = a + noise\n",
    "\n",
    "    pos = torch.empty(nb, device = device).uniform_(0.0, 0.5)\n",
    "    b1 = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    b1 = b1 - pos.view(nb, 1)\n",
    "    b1 = (b1 >= 0).float() * torch.exp(-b1 * math.log(2) / 0.1) * 0.25\n",
    "    pos = pos + hb.float() / (args.nb_classes + 1) * 0.5\n",
    "    # pos += pos.new(hb.size()).uniform_(0.0, 0.01)\n",
    "    b2 = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    b2 = b2 - pos.view(nb, 1)\n",
    "    b2 = (b2 >= 0).float() * torch.exp(-b2 * math.log(2) / 0.1) * 0.25\n",
    "\n",
    "    b = b1 + b2\n",
    "    noise = b.new(b.size()).normal_(0, noise_level)\n",
    "    b = b + noise\n",
    "\n",
    "    return a, b, ha\n",
    "\n",
    "class NetForImagePair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetForImagePair, self).__init__()\n",
    "        self.features_a = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.features_b = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(256, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = self.features_a(a).view(a.size(0), -1)\n",
    "        b = self.features_b(b).view(b.size(0), -1)\n",
    "        x = torch.cat((a, b), 1)\n",
    "        return self.fully_connected(x)\n",
    "\n",
    "class NetForImageValuesPair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetForImageValuesPair, self).__init__()\n",
    "        self.features_a = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.features_b = nn.Sequential(\n",
    "            nn.Linear(2, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 128), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(256, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = self.features_a(a).view(a.size(0), -1)\n",
    "        b = self.features_b(b).view(b.size(0), -1)\n",
    "        x = torch.cat((a, b), 1)\n",
    "        return self.fully_connected(x)\n",
    "\n",
    "class NetForSequencePair(nn.Module):\n",
    "\n",
    "    def feature_model(self):\n",
    "        kernel_size = 11\n",
    "        pooling_size = 4\n",
    "        return  nn.Sequential(\n",
    "            nn.Conv1d(      1, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetForSequencePair, self).__init__()\n",
    "\n",
    "        self.nc = 32\n",
    "        self.nh = 256\n",
    "\n",
    "        self.features_a = self.feature_model()\n",
    "        self.features_b = self.feature_model()\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(2 * self.nc, self.nh),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.nh, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = a.view(a.size(0), 1, a.size(1))\n",
    "        a = self.features_a(a)\n",
    "        a = F.avg_pool1d(a, a.size(2))\n",
    "\n",
    "        b = b.view(b.size(0), 1, b.size(1))\n",
    "        b = self.features_b(b)\n",
    "        b = F.avg_pool1d(b, b.size(2))\n",
    "\n",
    "        x = torch.cat((a.view(a.size(0), -1), b.view(b.size(0), -1)), 1)\n",
    "        return self.fully_connected(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]],\n",
      "\n",
      "\n",
      "        [[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]],\n",
      "\n",
      "\n",
      "        [[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]],\n",
      "\n",
      "\n",
      "        [[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]],\n",
      "\n",
      "\n",
      "        [[[-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          ...,\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240],\n",
      "          [-0.4240, -0.4240, -0.4240,  ..., -0.4240, -0.4240, -0.4240]]]])\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "torch.manual_seed(567)\n",
    "used_MNIST_classes = torch.tensor(eval('[' + \"1,2,3\" + ']'), device = device)\n",
    "print(used_MNIST_classes)\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./data/mnist/', train = True, download = True)\n",
    "train_input  = train_set.train_data.view(-1, 1, 28, 28).to(device).float()\n",
    "train_target = train_set.train_labels.to(device)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('./data/mnist/', train = False, download = True)\n",
    "test_input  = test_set.test_data.view(-1, 1, 28, 28).to(device).float()\n",
    "test_target = test_set.test_labels.to(device)\n",
    "\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "print(test_input.sub_(mu).div_(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_parameters 78097\n",
      "1 0.8022 1.5829\n",
      "2 1.3375 1.5829\n",
      "3 1.3859 1.5829\n",
      "4 1.4707 1.5829\n",
      "5 1.4897 1.5829\n",
      "6 1.5304 1.5829\n",
      "7 1.5546 1.5829\n",
      "8 1.5434 1.5829\n",
      "9 1.5904 1.5829\n",
      "10 1.5798 1.5829\n",
      "11 1.5826 1.5829\n",
      "12 1.6215 1.5829\n",
      "13 1.6321 1.5829\n",
      "14 1.6036 1.5829\n",
      "15 1.5999 1.5829\n",
      "16 1.5914 1.5829\n",
      "17 1.6150 1.5829\n",
      "18 1.6533 1.5829\n",
      "19 1.6242 1.5829\n",
      "20 1.6444 1.5829\n",
      "21 1.6525 1.5829\n",
      "22 1.6561 1.5829\n",
      "23 1.6323 1.5829\n",
      "24 1.6690 1.5829\n",
      "25 1.6639 1.5829\n",
      "26 1.6546 1.5829\n",
      "27 1.6375 1.5829\n",
      "28 1.6607 1.5829\n",
      "29 1.7044 1.5829\n",
      "30 1.6648 1.5829\n",
      "31 1.6305 1.5829\n",
      "32 1.6676 1.5829\n",
      "33 1.6546 1.5829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5f8cda573817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create pair and train\n",
    "# if args.data == 'image_pair':\n",
    "#     create_pairs = create_image_pairs\n",
    "#     model = NetForImagePair()\n",
    "# elif args.data == 'image_values_pair':\n",
    "#     create_pairs = create_image_values_pairs\n",
    "#     model = NetForImageValuesPair()\n",
    "# elif args.data == 'sequence_pair':\n",
    "#     create_pairs = create_sequences_pairs\n",
    "#     model = NetForSequencePair()\n",
    "\n",
    "#     ######################\n",
    "#     ## Save for figures\n",
    "#     a, b, c = create_pairs()\n",
    "#     for k in range(10):\n",
    "#         file = open(f'train_{k:02d}.dat', 'w')\n",
    "#         for i in range(a.size(1)):\n",
    "#             file.write(f'{a[k, i]:f} {b[k,i]:f}\\n')\n",
    "#         file.close()\n",
    "\n",
    "create_pairs = create_image_pairs\n",
    "model = NetForImagePair()\n",
    "nb_epochs = 50\n",
    "learning_rate = 0.0008\n",
    "batch_size = 20\n",
    "\n",
    "######################################################################\n",
    "# Train\n",
    "\n",
    "print(f'nb_parameters {sum(x.numel() for x in model.parameters())}')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "input_a, input_b, classes = create_pairs(train = True)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    input_br = input_b[torch.randperm(input_b.size(0))]\n",
    "\n",
    "    acc_mi = 0.0\n",
    "\n",
    "    for batch_a, batch_b, batch_br in zip(input_a.split(batch_size),input_b.split(batch_size),input_br.split(batch_size)):\n",
    "        mi = model(batch_a, batch_b).mean() - model(batch_a, batch_br).exp().mean().log()\n",
    "        acc_mi += mi.item()\n",
    "        loss = - mi\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc_mi /= (input_a.size(0) // batch_size)\n",
    "\n",
    "    print(f'{e+1} {acc_mi / math.log(2):.04f} {entropy(classes) / math.log(2):.04f}')\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "######################################################################\n",
    "# Test\n",
    "\n",
    "input_a, input_b, classes = create_pairs(train = False)\n",
    "input_br = input_b[torch.randperm(input_b.size(0))]\n",
    "acc_mi = 0.0\n",
    "\n",
    "for batch_a, batch_b, batch_br in zip(input_a.split(batch_size),input_b.split(batch_size),input_br.split(batch_size)):\n",
    "    mi = model(batch_a, batch_b).mean() - model(batch_a, batch_br).exp().mean().log()\n",
    "    acc_mi += mi.item()\n",
    "\n",
    "acc_mi /= (input_a.size(0) // args.batch_size)\n",
    "\n",
    "print(f'test {acc_mi / math.log(2):.04f} {entropy(classes) / math.log(2):.04f}')\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code: https://fleuret.org/files/mi_estimator.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T02:04:07.260295Z",
     "start_time": "2019-01-16T02:04:06.676338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data DATA] [--seed SEED]\n",
      "                             [--mnist_classes MNIST_CLASSES]\n",
      "                             [--nb_classes NB_CLASSES] [--nb_epochs NB_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--learning_rate LEARNING_RATE] [--independent]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\JDSeo\\AppData\\Roaming\\jupyter\\runtime\\kernel-3b976bd8-e2d7-4c5a-8248-86e8cff36f59.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "#########################################################################\n",
    "# This program is free software: you can redistribute it and/or modify  #\n",
    "# it under the terms of the version 3 of the GNU General Public License #\n",
    "# as published by the Free Software Foundation.                         #\n",
    "#                                                                       #\n",
    "# This program is distributed in the hope that it will be useful, but   #\n",
    "# WITHOUT ANY WARRANTY; without even the implied warranty of            #\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU      #\n",
    "# General Public License for more details.                              #\n",
    "#                                                                       #\n",
    "# You should have received a copy of the GNU General Public License     #\n",
    "# along with this program. If not, see <http://www.gnu.org/licenses/>.  #\n",
    "#                                                                       #\n",
    "# Written by Francois Fleuret, (C) Idiap Research Institute             #\n",
    "#                                                                       #\n",
    "# Contact <francois.fleuret@idiap.ch> for comments & bug reports        #\n",
    "#########################################################################\n",
    "\n",
    "import argparse, math, sys\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch, torchvision\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "######################################################################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "######################################################################\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = '''An implementation of a Mutual Information estimator with a deep model\n",
    "\n",
    "    Three different toy data-sets are implemented, each consists of\n",
    "    pairs of samples, that may be from different spaces:\n",
    "\n",
    "    (1) Two MNIST images of same class. The \"true\" MI is the log of the\n",
    "    number of used MNIST classes.\n",
    "\n",
    "    (2) One MNIST image and a pair of real numbers whose difference is\n",
    "    the class of the image. The \"true\" MI is the log of the number of\n",
    "    used MNIST classes.\n",
    "\n",
    "    (3) Two 1d sequences, the first with a single peak, the second with\n",
    "    two peaks, and the height of the peak in the first is the\n",
    "    difference of timing of the peaks in the second. The \"true\" MI is\n",
    "    the log of the number of possible peak heights.''',\n",
    "\n",
    "    formatter_class = argparse.ArgumentDefaultsHelpFormatter\n",
    ")\n",
    "\n",
    "parser.add_argument('--data',\n",
    "                    type = str, default = 'image_pair',\n",
    "                    help = 'What data: image_pair, image_values_pair, sequence_pair')\n",
    "\n",
    "parser.add_argument('--seed',\n",
    "                    type = int, default = 0,\n",
    "                    help = 'Random seed (default 0, < 0 is no seeding)')\n",
    "\n",
    "parser.add_argument('--mnist_classes',\n",
    "                    type = str, default = '0, 1, 3, 5, 6, 7, 8, 9',\n",
    "                    help = 'What MNIST classes to use')\n",
    "\n",
    "parser.add_argument('--nb_classes',\n",
    "                    type = int, default = 2,\n",
    "                    help = 'How many classes for sequences')\n",
    "\n",
    "parser.add_argument('--nb_epochs',\n",
    "                    type = int, default = 50,\n",
    "                    help = 'How many epochs')\n",
    "\n",
    "parser.add_argument('--batch_size',\n",
    "                    type = int, default = 100,\n",
    "                    help = 'Batch size')\n",
    "\n",
    "parser.add_argument('--learning_rate',\n",
    "                    type = float, default = 1e-3,\n",
    "                    help = 'Batch size')\n",
    "\n",
    "parser.add_argument('--independent', action = 'store_true',\n",
    "                    help = 'Should the pair components be independent')\n",
    "\n",
    "######################################################################\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.seed >= 0:\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "used_MNIST_classes = torch.tensor(eval('[' + args.mnist_classes + ']'), device = device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T02:04:32.340816Z",
     "start_time": "2019-01-16T02:04:17.515110Z"
    },
    "code_folding": [
     2,
     26,
     61,
     92,
     126,
     155,
     183
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "\n",
    "def entropy(target):\n",
    "    probas = []\n",
    "    for k in range(target.max() + 1):\n",
    "        n = (target == k).sum().item()\n",
    "        if n > 0: probas.append(n)\n",
    "    probas = torch.tensor(probas).float()\n",
    "    probas /= probas.sum()\n",
    "    return - (probas * probas.log()).sum().item()\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./data/mnist/', train = True, download = True)\n",
    "train_input  = train_set.train_data.view(-1, 1, 28, 28).to(device).float()\n",
    "train_target = train_set.train_labels.to(device)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('./data/mnist/', train = False, download = True)\n",
    "test_input = test_set.test_data.view(-1, 1, 28, 28).to(device).float()\n",
    "test_target = test_set.test_labels.to(device)\n",
    "\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "test_input.sub_(mu).div_(std)\n",
    "\n",
    "# Returns a triplet of tensors (a, b, c), where a and b contain each\n",
    "# half of the samples, with a[i] and b[i] of same class for any i, and\n",
    "# c is a 1d long tensor real classes\n",
    "def create_image_pairs(train = False):\n",
    "    ua, ub, uc = [], [], []\n",
    "\n",
    "    if train:\n",
    "        input, target = train_input, train_target\n",
    "    else:\n",
    "        input, target = test_input, test_target\n",
    "\n",
    "    for i in used_MNIST_classes:\n",
    "        used_indices = torch.arange(input.size(0), device = target.device)\\\n",
    "                            .masked_select(target == i.item())\n",
    "        x = input[used_indices]\n",
    "        x = x[torch.randperm(x.size(0))]\n",
    "        hs = x.size(0)//2\n",
    "        ua.append(x.narrow(0, 0, hs))\n",
    "        ub.append(x.narrow(0, hs, hs))\n",
    "        uc.append(target[used_indices])\n",
    "\n",
    "    a = torch.cat(ua, 0)\n",
    "    b = torch.cat(ub, 0)\n",
    "    c = torch.cat(uc, 0)\n",
    "    perm = torch.randperm(a.size(0))\n",
    "    a = a[perm].contiguous()\n",
    "\n",
    "    if args.independent:\n",
    "        perm = torch.randperm(a.size(0))\n",
    "    b = b[perm].contiguous()\n",
    "\n",
    "    return a, b, c\n",
    "\n",
    "# Returns a triplet a, b, c where a are the standard MNIST images, c\n",
    "# the classes, and b is a Nx2 tensor, with for every n:\n",
    "#\n",
    "#   b[n, 0] ~ Uniform(0, 10)\n",
    "#   b[n, 1] ~ b[n, 0] + Uniform(0, 0.5) + c[n]\n",
    "def create_image_values_pairs(train = False):\n",
    "    ua, ub = [], []\n",
    "\n",
    "    if train:\n",
    "        input, target = train_input, train_target\n",
    "    else:\n",
    "        input, target = test_input, test_target\n",
    "\n",
    "    m = torch.zeros(used_MNIST_classes.max() + 1, dtype = torch.uint8, device = target.device)\n",
    "    m[used_MNIST_classes] = 1\n",
    "    m = m[target]\n",
    "    used_indices = torch.arange(input.size(0), device = target.device).masked_select(m)\n",
    "\n",
    "    input = input[used_indices].contiguous()\n",
    "    target = target[used_indices].contiguous()\n",
    "\n",
    "    a = input\n",
    "    c = target\n",
    "\n",
    "    b = a.new(a.size(0), 2)\n",
    "    b[:, 0].uniform_(0.0, 10.0)\n",
    "    b[:, 1].uniform_(0.0, 0.5)\n",
    "\n",
    "    if args.independent:\n",
    "        b[:, 1] += b[:, 0] + \\\n",
    "                   used_MNIST_classes[torch.randint(len(used_MNIST_classes), target.size())]\n",
    "    else:\n",
    "        b[:, 1] += b[:, 0] + target.float()\n",
    "\n",
    "    return a, b, c\n",
    "\n",
    "def create_sequences_pairs(train = False):\n",
    "    nb, length = 10000, 1024\n",
    "    noise_level = 2e-2\n",
    "\n",
    "    ha = torch.randint(args.nb_classes, (nb, ), device = device) + 1\n",
    "    if args.independent:\n",
    "        hb = torch.randint(args.nb_classes, (nb, ), device = device)\n",
    "    else:\n",
    "        hb = ha\n",
    "\n",
    "    pos = torch.empty(nb, device = device).uniform_(0.0, 0.9)\n",
    "    a = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    a = a - pos.view(nb, 1)\n",
    "    a = (a >= 0).float() * torch.exp(-a * math.log(2) / 0.1)\n",
    "    a = a * ha.float().view(-1, 1).expand_as(a) / (1 + args.nb_classes)\n",
    "    noise = a.new(a.size()).normal_(0, noise_level)\n",
    "    a = a + noise\n",
    "\n",
    "    pos = torch.empty(nb, device = device).uniform_(0.0, 0.5)\n",
    "    b1 = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    b1 = b1 - pos.view(nb, 1)\n",
    "    b1 = (b1 >= 0).float() * torch.exp(-b1 * math.log(2) / 0.1) * 0.25\n",
    "    pos = pos + hb.float() / (args.nb_classes + 1) * 0.5\n",
    "    # pos += pos.new(hb.size()).uniform_(0.0, 0.01)\n",
    "    b2 = torch.linspace(0, 1, length, device = device).view(1, -1).expand(nb, -1)\n",
    "    b2 = b2 - pos.view(nb, 1)\n",
    "    b2 = (b2 >= 0).float() * torch.exp(-b2 * math.log(2) / 0.1) * 0.25\n",
    "\n",
    "    b = b1 + b2\n",
    "    noise = b.new(b.size()).normal_(0, noise_level)\n",
    "    b = b + noise\n",
    "\n",
    "    return a, b, ha\n",
    "\n",
    "class NetForImagePair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetForImagePair, self).__init__()\n",
    "        self.features_a = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.features_b = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(256, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = self.features_a(a).view(a.size(0), -1)\n",
    "        b = self.features_b(b).view(b.size(0), -1)\n",
    "        x = torch.cat((a, b), 1)\n",
    "        return self.fully_connected(x)\n",
    "\n",
    "class NetForImageValuesPair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetForImageValuesPair, self).__init__()\n",
    "        self.features_a = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.MaxPool2d(3), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5),\n",
    "            nn.MaxPool2d(2), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.features_b = nn.Sequential(\n",
    "            nn.Linear(2, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 128), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(256, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = self.features_a(a).view(a.size(0), -1)\n",
    "        b = self.features_b(b).view(b.size(0), -1)\n",
    "        x = torch.cat((a, b), 1)\n",
    "        return self.fully_connected(x)\n",
    "\n",
    "class NetForSequencePair(nn.Module):\n",
    "\n",
    "    def feature_model(self):\n",
    "        kernel_size = 11\n",
    "        pooling_size = 4\n",
    "        return  nn.Sequential(\n",
    "            nn.Conv1d(      1, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(self.nc, self.nc, kernel_size = kernel_size),\n",
    "            nn.AvgPool1d(pooling_size),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetForSequencePair, self).__init__()\n",
    "\n",
    "        self.nc = 32\n",
    "        self.nh = 256\n",
    "\n",
    "        self.features_a = self.feature_model()\n",
    "        self.features_b = self.feature_model()\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(2 * self.nc, self.nh),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.nh, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = a.view(a.size(0), 1, a.size(1))\n",
    "        a = self.features_a(a)\n",
    "        a = F.avg_pool1d(a, a.size(2))\n",
    "\n",
    "        b = b.view(b.size(0), 1, b.size(1))\n",
    "        b = self.features_b(b)\n",
    "        b = F.avg_pool1d(b, b.size(2))\n",
    "\n",
    "        x = torch.cat((a.view(a.size(0), -1), b.view(b.size(0), -1)), 1)\n",
    "        return self.fully_connected(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "if args.data == 'image_pair':\n",
    "    create_pairs = create_image_pairs\n",
    "    model = NetForImagePair()\n",
    "\n",
    "elif args.data == 'image_values_pair':\n",
    "    create_pairs = create_image_values_pairs\n",
    "    model = NetForImageValuesPair()\n",
    "\n",
    "elif args.data == 'sequence_pair':\n",
    "    create_pairs = create_sequences_pairs\n",
    "    model = NetForSequencePair()\n",
    "\n",
    "    ######################\n",
    "    ## Save for figures\n",
    "    a, b, c = create_pairs()\n",
    "    for k in range(10):\n",
    "        file = open(f'train_{k:02d}.dat', 'w')\n",
    "        for i in range(a.size(1)):\n",
    "            file.write(f'{a[k, i]:f} {b[k,i]:f}\\n')\n",
    "        file.close()\n",
    "    ######################\n",
    "\n",
    "else:\n",
    "    raise Exception('Unknown data ' + args.data)\n",
    "\n",
    "# Train\n",
    "print(f'nb_parameters {sum(x.numel() for x in model.parameters())}')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "input_a, input_b, classes = create_pairs(train = True)\n",
    "\n",
    "for e in range(args.nb_epochs):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "    input_br = input_b[torch.randperm(input_b.size(0))]\n",
    "\n",
    "    acc_mi = 0.0\n",
    "\n",
    "    for batch_a, batch_b, batch_br in zip(input_a.split(args.batch_size),\n",
    "                                          input_b.split(args.batch_size),\n",
    "                                          input_br.split(args.batch_size)):\n",
    "        mi = model(batch_a, batch_b).mean() - model(batch_a, batch_br).exp().mean().log()\n",
    "        acc_mi += mi.item()\n",
    "        loss = - mi\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc_mi /= (input_a.size(0) // args.batch_size)\n",
    "\n",
    "    print(f'{e+1} {acc_mi / math.log(2):.04f} {entropy(classes) / math.log(2):.04f}')\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Test\n",
    "input_a, input_b, classes = create_pairs(train = False)\n",
    "input_br = input_b[torch.randperm(input_b.size(0))]\n",
    "acc_mi = 0.0\n",
    "\n",
    "for batch_a, batch_b, batch_br in zip(input_a.split(args.batch_size),\n",
    "                                      input_b.split(args.batch_size),\n",
    "                                      input_br.split(args.batch_size)):\n",
    "    mi = model(batch_a, batch_b).mean() - model(batch_a, batch_br).exp().mean().log()\n",
    "    acc_mi += mi.item()\n",
    "\n",
    "acc_mi /= (input_a.size(0) // args.batch_size)\n",
    "\n",
    "print(f'test {acc_mi / math.log(2):.04f} {entropy(classes) / math.log(2):.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
